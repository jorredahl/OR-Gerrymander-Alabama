---
title: "Gerrymandering in Alabama"
author: "Jorre Dahl"
date: "`r Sys.Date()`"
output: html_document
editor_options:
  markdown:
    wrap: sentence
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../../docs/report") })
---

# Abstract

This is a study of gerrymandering in Alabama.
We will test three methods of shape-based compactness scores, assess representativeness of districts based on prior presidential elections and race.
We will then extend prior studies by calculating representativeness of the convex hull of district polygons.

# Study metadata

- `Key words`: Gerrymandering, Compactness, Gerrymandering, Convex Hull, Political Representation.
- `Subject`: Social and Behavioral Sciences: Geography: Geographic Information Sciences
- `Date created`: 2025-02-17
- `Date modified`: 2025-02-17
- `Spatial Coverage`: Alabama OSM:[161950](https://www.openstreetmap.org/relation/161950)
- `Spatial Resolution`: Census Block Groups
- `Spatial Reference System`: EPSG:4269 NAD 1983 Geographic Coordinate System
- `Temporal Coverage`: 2020-2024 population and voting data
- `Temporal Resolution`: Decennial census

# Study design

This is an original study based on literature on gerrymandering metrics.

It is an exploratory study to evaluate usefulness of a new gerrymandering metric based on the convex hull of a congressional district and the representativeness inside the convex hull compared to the congressional district.

Describe how the study relates to prior literature, e.g. is it a **original study**, **meta-analysis study**, **reproduction study**, **reanalysis study**, or **replication study**?

Also describe the original study archetype, e.g. is it **observational**, **experimental**, **quasi-experimental**, or **exploratory**?

Enumerate specific **hypotheses** to be tested or **research questions** to be investigated here, and specify the type of method, statistical test or model to be used on the hypothesis or question.

# Materials and procedure

## Computational environment

I plan on using ... package for ...

```{r environment-setup, include = FALSE, eval = FALSE, echo = TRUE}
# record all the packages you are using here
# this includes any calls to library(), require(),
# and double colons such as here::i_am()
packages <- c("tidyverse", "here", "sf", "tmap", "tidycensus", "lwgeom")

# force all conflicts to become errors
# if you load dplyr and use filter(), R has to guess whether you mean dplyr::filter() or stats::filter()
# the conflicted package forces you to be explicit about this
# disable at your own peril
# https://conflicted.r-lib.org/
require(conflicted)

# load and install required packages
# https://groundhogr.com/
if (!require(groundhog)) {
  install.packages("groundhog")
  require(groundhog)
}

# this date will be used to determine the versions of R and your packages
# it is best practice to keep R and its packages up to date
groundhog.day <- "2025-02-19"

# this replaces any library() or require() calls
groundhog.library(packages, groundhog.day)
# you may need to install a correct version of R
# you may need to respond OK in the console to permit groundhog to install packages
# you may need to restart R and rerun this code to load installed packages
# In RStudio, restart r with Session -> Restart Session

# record the R processing environment
# alternatively, use devtools::session_info() for better results
writeLines(
  capture.output(sessionInfo()),
  here("procedure", "environment", paste0("r-environment-", Sys.Date(), ".txt"))
)

# save package citations
knitr::write_bib(c(packages, "base"), file = here("software.bib"))

# set up default knitr parameters
# https://yihui.org/knitr/options/
knitr::opts_chunk$set(
  echo = FALSE, # Run code, show outputs (don't show code)
  fig.retina = 4,
  fig.width = 8,
  fig.path = paste0(here("results", "figures"), "/")
)
```

## Data and variables

We plan on using data scources: precincts20 districts23, blockgroups2020

### Precincts 2020 (Secondary)

- `Title`: Voting Precincts 2020
- `Abstract`: Alabama voting data for 2020 elections by precinct.
- `Spatial Coverage`: Alabama
- `Spatial Resolution`: Voting precincts
- `Spatial Reference System`: EPSG 4269 NAD 1983 Geographic Coordinate System
- `Temporal Coverage`: voting precincts used for tabulating the 2020 election
- `Temporal Resolution`: annual election
- `Lineage`: Saved as geopackage format. Processing prior to download is explained in al_vest_20_validation_report.pdf
- `Distribution`: Data available at Redistricting Data Hub
- `Constraints`: Permitted for noncommercial and nonpartisan use only. Copyright and use constraints explained in redistrictingdatahub_legal.txt
- `Data Quality`: State any planned quality assessment
- `Variables`: For each variable, enter the following information. If you have two or more variables per data source, you may want to present this information in table form (shown below)
  - `Label`: variable name as used in the data or code
  - `Alias`: intuitive natural language name
  - `Definition`: Short description or definition of the variable. Include measurement units in description.
  - `Type`: data type, e.g. character string, integer, real
  - `Accuracy`: e.g. uncertainty of measurements
  - `Domain`: Expected range of Maximum and Minimum of numerical data, or codes or categories of nominal data, or reference to a standard codebook
  - `Missing Data Value(s)`: Values used to represent missing data and frequency of missing data observations
  - `Missing Data Frequency`: Frequency of missing data observations: not yet known for data to be collected

| Label | Alias | Definition | Type | Accuracy | Domain | Missing Data Value(s) | Missing Data Frequency |
| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
| VTDST20 | ... | Voting district ID | ... | ... | ... | ... | ... |
| GEOID20 | ... | Unique Geographic ID | ... | ... | ... | ... | ... |
| G20PRERTRU | ... | total votes for Trump in 2020 | ... | ... | ... | ... | ... |
| G20PREDBID | ... | total votes for Biden in 2020 | ... | ... | ... | ... | ... |

```{r, include = TRUE, eval = FALSE, echo = TRUE}
library(sf)

precincts20 <- st_read(here("data","raw","public","districts.gpkg"), layer = "precincts20")
```

### Districts 2023 (Primary)

- `Title`: Voting Districts 2024
- `Abstract`: Alabama voitng districts approved in 2023 for use in 2024
- `Spatial Coverage`: Alabama
- `Spatial Resolution`: US Congressional Districts
- `Spatial Reference System`: EPSG 3857 WGS 1984 Web Mercator projection
- `Temporal Coverage`: approved in 2023 for 2024 use
- `Temporal Resolution`: districting based on 2020 census data (updated every 10 years)
- `Lineage`: Loaded into QGIS as ArcGIS feature service layer and saved in geopackage format. Extraneous data fields were removed and the FIX GEOMETRIES tool was used to correct geometry errors.
- `Distribution`: Alabama State GIS via ESRI feature service at <https://services7.arcgis.com/jF2q3LPxL7PETdYk/arcgis/rest/services/2023_Court_Ordered_Congressional_Plan/FeatureServer>
- `Constraints`: Public Domain data free for use and redistribution.
- `Data Quality`: State any planned quality assessment
- `Variables`: For each variable, enter the following information. If you have two or more variables per data source, you may want to present this information in table form (shown below)
  - `Label`: variable name as used in the data or code
  - `Alias`: intuitive natural language name
  - `Definition`: Short description or definition of the variable. Include measurement units in description.
  - `Type`: data type, e.g. character string, integer, real
  - `Accuracy`: e.g. uncertainty of measurements
  - `Domain`: Expected range of Maximum and Minimum of numerical data, or codes or categories of nominal data, or reference to a standard codebook
  - `Missing Data Value(s)`: Values used to represent missing data and frequency of missing data observations
  - `Missing Data Frequency`: Frequency of missing data observations: not yet known for data to be collected

| Label | Alias | Definition | Type | Accuracy | Domain | Missing Data Value(s) | Missing Data Frequency |
| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
| DISTRICT | ... | US Congressional District Number | ... | ... | ... | ... | ... |
| POPULATION | ... | total population (2020 census) | ... | ... | ... | ... | ... |
| WHITE | ... | total white population (2020 census) | ... | ... | ... | ... | ... |
| BLACK | ... | total black population (2020 census) | ... | ... | ... | ... | ... |

```{r, include = TRUE, eval = FALSE, echo = TRUE}
districts23 <- st_read(here("data","raw","public","districts.gpkg"), layer = "districts23")
```

### Block Groups 2020 (Primary)

- `Title`: 2020 Census block groups
- `Abstract`: Vector polygon layer of census block groups and their demographic data
- `Spatial Coverage`: Alabama
- `Spatial Resolution`: Census block groups
- `Spatial Reference System`: EPSG 4269 NAD 1983 Geographic Coordinate System
- `Temporal Coverage`: 2020 census
- `Temporal Resolution`: 10-year census
- `Lineage`: Downloaded data from US Census API "p1" public law summary file using tidycensus in R.
- `Distribution`: US Census API
- `Constraints`: Public Domain data free for use and redistribution.
- `Data Quality`: State any planned quality assessment
- `Variables`: For each variable, enter the following information. If you have two or more variables per data source, you may want to present this information in table form (shown below)
  - `Label`: variable name as used in the data or code
  - `Alias`: intuitive natural language name
  - `Definition`: Short description or definition of the variable. Include measurement units in description.
  - `Type`: data type, e.g. character string, integer, real
  - `Accuracy`: e.g. uncertainty of measurements
  - `Domain`: Expected range of Maximum and Minimum of numerical data, or codes or categories of nominal data, or reference to a standard codebook
  - `Missing Data Value(s)`: Values used to represent missing data and frequency of missing data observations
  - `Missing Data Frequency`: Frequency of missing data observations: not yet known for data to be collected

| Label | Alias | Definition | Type | Accuracy | Domain | Missing Data Value(s) | Missing Data Frequency |
| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
| GEOID | ... | Code to uniquely identify tracts | ... | ... | ... | ... | ... |
| P4_001N | ... | Total Population, 18 years or older | ... | ... | ... | ... | ... |
| P4006N | ... | Total: Not Hispanic or Latino, Population of one race, Black or African American alone, 18 years or older | ... | ... | ... | ... | ... |
| G20PREDBID | ... | Total institutionalized population in correctional facilities for adults 18 years or older | ... | ... | ... | ... | ... |

```{r, include = TRUE, eval = FALSE, echo = TRUE}
library(tidycensus)

census_metadata_file <- here("data", "metadata", "census2020pl_vars.csv")
if(file.exists(census_metadata_file)){
  census2020pl_vars <- read.csv(census_metadata_file)
} else {
  census2020pl_vars <- load_variables(2020, "pl")
  write.csv(census2020pl_vars, here("data", "metadata", "census2020pl_vars.csv"))
}
blockgroup_file <- here("data", "raw", "public", "block_groups.gpkg")

# if the data is already downloaded, just load it
# otherwise, query from the census and save
if(file.exists(blockgroup_file)){
  blockgroups <- st_read(blockgroup_file)
} else {
  blockgroups <- get_decennial(geography = "block group",
                               sumfile = "pl",
                               table = "P3",
                               year = 2020,
                               state = "Alabama",
                               output = "wide",
                               geometry = TRUE,
                               keep_geo_vars = TRUE)
  st_write(blockgroups, blockgroup_file)
}
```

## Prior observations  

I have not looked at this data before.

## Bias and threats to validity

Modifiable Areal Unit Problem: demographic data is collected at both the district and the block level
  - This experiment tries to combat many of the problems with edge effects associated with studies of gerrymandering.

## Data transformations

### Calculate Percent Black

Find the sum of Black or African American people by gathering all variables that include the term "Black".

```{r eval = FALSE, echo = TRUE}
library(tidyverse)

black_vars <- census2020pl_vars |> 
  dplyr::filter(str_detect(name, "P3"),
                str_detect(label, "Black")) |> 
  select(-concept)
```

Next, calculate new columns.
`Black` : sum of all columns as any combination of groups including black
`Total` : equal to `P3_001N`, total population 18 or over
`PctBlack` : Percentage of people listed in `Black`
`CheckPct` : sum of `P3_003N` and `Black` percentages, this value should not exceed 100%.

```{r eval = FALSE, echo = TRUE}
blockgroups_calc <- blockgroups |> 
  rowwise() |> 
  mutate(Black = sum(c_across(all_of(black_vars$name)))) |> 
  ungroup() |> 
  mutate(Total = P3_001N,
         PctBlack = Black / Total * 100,
         CheckPct = (Black + P3_003N) / Total * 100) |> 
  select(GEOID, Black, Total, PctBlack, CheckPct)
```

Save the results as blockgroups_calc.gpkg

```{r eval=FALSE, echo = TRUE}
st_write(blockgroups_calc, 
         here("data", "derived", "public", "blockgroups_calc.gpkg"),
         append=FALSE)
```
Map Results

```{r eval = FALSE, echo = TRUE}
library(tmap)

tm_shape(blockgroups_calc) + 
  tm_polygons(
    fill = "PctBlack",
    col_alpha = 0.2,
    lwd = 0.1,
    col = "grey90"
  )
```

### Calculate District Variables

Calculate the compactness of each district using the Polsby-Popper isoperimetric ratio through elipsoidal area and perimeter calculations.

```{r eval = FALSE, echo = TRUE}
sf_use_s2(FALSE)

districts23 <- districts23 |>
  mutate(
    area = st_area(geom),
    perim = st_length(st_cast(st_cast(geom, "MULTIPOLYGON"), "MULTILINESTRING")),
    ppir_compact = round(as.numeric((4 * pi * area) / perim^2),2)
  )
```

Calculate the compactness of each district using the ratio of convex-hull area to actual area

```{r eval = FALSE, echo = TRUE}
sf_use_s2(FALSE)

districts23_hull <- districts23 |> st_convex_hull()

districts23_hull <- districts23_hull |>
  mutate(
    hullarea = st_area(geom)
  )

districts23 <- districts23 |>
  mutate(
    hullarea = districts23_hull$hullarea[match(DISTRICT, districts23_hull$DISTRICT)],
    ch_compact = round(as.numeric(area / hullarea),2)
  )
```

Calculate the compactness of each district using the ratio of minimum bounding circle area to actual area

```{r eval = FALSE, echo = TRUE}
library(lwgeom)
sf_use_s2(FALSE)

districts23_mbcircle <- districts23 |> st_minimum_bounding_circle()

districts23_mbcircle <- districts23_mbcircle |>
  mutate(
    circlearea = st_area(geom)
  )

districts23 <- districts23 |>
  mutate(
    circlearea = districts23_mbcircle$circlearea[match(DISTRICT, districts23_mbcircle$DISTRICT)],
    mbc_compact = round(as.numeric(area / circlearea),2)
  )
```

Area weighted re-aggregation to gather Percent Democrat in each district. Using precincts20 layer and assuming population stays constant across each voting precinct.

The intersection of voting precincts and districts was gathered, calculating the area of each precinct beforehand. Then an area weight was assigned to each fragment, where the weighted democrat vote count and weighted total vote count is counted. Using these values to re-aggregate by district, I summarize by district to get vote counts for each, getting percent democrat in each district.

For area weighted re-aggregation, there is a level of bias stemming from the assumption that pieces of the geometry becoming fragmented are spatially homogenous. While this experiment acknowleges that this is not possible, an area weighted re-aggregation at a small scale of voting precinct or census block group minimizes this bias.

```{r eval = FALSE, echo = TRUE}
sf_use_s2(FALSE)

precincts20 <- precincts20 |>
  st_transform(crs = 4269) |>
  mutate(
    precinctarea = st_area(geom),
    total_vote = G20PRERTRU + G20PREDBID
  )

precincts_int_districts <- st_intersection(precincts20, districts23) |>
  mutate(f_area = st_area(geom),
         aw = as.numeric(f_area / precinctarea),
         aw_dem = aw * G20PREDBID,
         aw_total = aw * total_vote)

districts_dem <- precincts_int_districts |>
  group_by(DISTRICT) |> 
  summarize(
    sumvote = sum(aw_total),
    sumdem = sum(aw_dem)
  ) |>
  mutate(
    pct_dem = as.numeric(sumdem / sumvote)
  )

districts23 <- districts23 |>
  mutate(
    pct_dem = districts_dem$pct_dem[match(DISTRICT, districts_dem$DISTRICT)]
  )
```

Area weighted re-aggregation to gather Percent Black in each district. Using blockgroups_calc layer and assuming population stays constant across each voting precinct.

The intersection of census block groups and districts was gathered, calculating the area of each block group beforehand. Then an area weight was assigned to each fragment, where the black population and weighted total population is counted. Using these values to re-aggregate by district, I summarize by district to get demographics for each, getting percent black in each district.

```{r eval = FALSE, echo = TRUE}
sf_use_s2(FALSE)

blockgroups_calc <- blockgroups_calc |>
  st_transform(crs = 4269) |>
  mutate(
    blockarea = st_area(geometry),
  )

blocks_int_districts <- st_intersection(blockgroups_calc, districts23) |>
  mutate(f_area = st_area(geometry),
         aw = as.numeric(f_area / blockarea),
         aw_black = aw * Black,
         aw_total = aw * Total)

districts_black <- blocks_int_districts |>
  group_by(DISTRICT) |> 
  summarize(
    sumblack = sum(aw_black),
    sumpop = sum(aw_total)
  ) |>
  mutate(
    pct_black = as.numeric(sumblack / sumpop)
  )

districts23 <- districts23 |>
  mutate(
    pct_black = districts_black$pct_black[match(DISTRICT, districts_black$DISTRICT)]
  )
```

## Analysis

Describe the methods of analysis that will directly test the hypotheses or provide results to answer the research questions.
This section should explicitly define any spatial / statistical *models* and their *parameters*, including *grouping* criteria, *weighting* criteria, and *significance thresholds*.
Also explain any follow-up analyses or validations.

### Find if districts are abnormally black

Using the convex hulls of the districts, we can perform area weighted re-aggregation on each for the block groups to find the percent black of areas surrounding the hull.

```{r eval = FALSE, echo = TRUE}
sf_use_s2(FALSE)

blocks_int_districtshull <- st_intersection(blockgroups_calc, districts23_hull) |>
  mutate(f_area = st_area(geometry),
         aw = as.numeric(f_area / hullarea),
         aw_black = aw * Black,
         aw_total = aw * Total)

districtshull_black <- blocks_int_districtshull |>
  group_by(DISTRICT) |> 
  summarize(
    sumblack = sum(aw_black),
    sumpop = sum(aw_total)
  ) |>
  mutate(
    pct_black = as.numeric(sumblack / sumpop)
  )

districts23 <- districts23 |>
  mutate(
    hull_pct_black = districtshull_black$pct_black[match(DISTRICT, districtshull_black$DISTRICT)]
  )
```

Now, I can calculate a metric for how unusually concentrated a district is with black voters through `pct_black - hull_pct_black`.

```{r eval = FALSE, echo = TRUE}
districts23 <- districts23 |>
  mutate(
    black_concentration_val = pct_black - hull_pct_black
  )
```

# Results

Here are values for districts and their percentages of black voting-age people.

```{r eval = FALSE, echo = TRUE}
tm_shape(districts23) + 
  tm_polygons(
    fill = "pct_black",
    col_alpha = 0.2,
    lwd = 0.1,
    col = "grey90"
  )
```

Here are values for districts and their percentages of democrat votes on main-ticket candidates in the 2020 presidential election.

```{r eval = FALSE, echo = TRUE}
tm_shape(districts23) + 
  tm_polygons(
    fill = "pct_dem",
    col_alpha = 0.2,
    lwd = 0.1,
    col = "grey90"
  )
```

Here are values for districts and their compactness values found through the Polsby-Popper isoperimetric ratio.

```{r eval = FALSE, echo = TRUE}
tm_shape(districts23) + 
  tm_polygons(
    fill = "ppir_compact",
    col_alpha = 0.2,
    lwd = 0.1,
    col = "grey90"
  )
```

Here are values for districts and their compactness values found through the ratio of area to convex hull area.

```{r eval = FALSE, echo = TRUE}
tm_shape(districts23) + 
  tm_polygons(
    fill = "ch_compact",
    col_alpha = 0.2,
    lwd = 0.1,
    col = "grey90"
  )
```

Here are values for districts and their compactness values found through the ratio of area to minimum bounding circle area.

```{r eval = FALSE, echo = TRUE}
tm_shape(districts23) + 
  tm_polygons(
    fill = "mbc_compact",
    col_alpha = 0.2,
    lwd = 0.1,
    col = "grey90"
  )
```

Here are values for districts on their score for black concentration. A higher number means black people are more unusually concetrated in this district.

```{r eval = FALSE, echo = TRUE}
tm_shape(districts23) + 
  tm_polygons(
    fill = "black_concentration_val",
    col_alpha = 0.2,
    lwd = 0.1,
    col = "grey90"
  )
```

Lastly here's a table with Each Precinct, and each of these calculated metricts.

```{r eval = FALSE, echo = TRUE}
as_tibble(districts23 |> select(DISTRICT, ppir_compact, ch_compact, mbc_compact, pct_dem, pct_black, black_concentration_val))
```

# Discussion

Here, you can see that districts 2 and 7 with the highest concentrations of black people over the age of 18 had the highest value of unusual concentration of black people, with an over 12% in black population percentage inside the district as compared to a district with the same shape as its convex hull.

While compactness might not be a great indicator of whether a district was unfairly created, statistics like these can illuminate the advantages for some and disadvantages for others maps like these create.

# Integrity Statement

I completed this preregistration to the best of my knowledge and that no other preregistration exists pertaining to the same hypotheses and research.

# Acknowledgements

This report is based upon the template for Reproducible and Replicable Research in Human-Environment and Geographical Sciences, DOI:[10.17605/OSF.IO/W29MQ](https://doi.org/10.17605/OSF.IO/W29MQ)

# References

  - Nüst, D., and E. Pebesma. 2021. Practical Reproducibility in Geography and Geosciences. Annals of the American Association of Geographers 111 (5):1300–1310. DOI:[10.1080/24694452.2020.1806028](https://www.tandfonline.com/doi/full/10.1080/24694452.2020.1806028).
  - Wilson, J. P., K. Butler, S. Gao, Y. Hu, W. Li, and D. J. Wright. 2021. A Five-Star Guide for Achieving Replicability and Reproducibility When Working with GIS Software and Algorithms. Annals of the American Association of Geographers 111 (5):1311–1317. DOI:[10.1080/24694452.2020.1806026](https://www.tandfonline.com/doi/full/10.1080/24694452.2020.1806026).
  - Ibanez, L., W. J. Schroeder, and M. D. Hanwell. 2014. Practicing open science. In Implementing Reproducible Research, eds. V. Stodden, F. Leisch, and R. D. Peng, 241–280. Boca Raton: CRC Press.
  - Millman, K. J., and F. Perez. 2014. Developing Open-Source Scientific Practice. In Implementing Reproducible Research, eds. V. Stodden, F. Leisch, and R. D. Peng, 149–183. Boca Raton: CRC Press.
  -Nüst, D., C. Boettiger, and B. Marwick. 2018. How to Read a Research Compendium. arXiv:[1806.09525](https://arxiv.org/abs/1806.09525).

